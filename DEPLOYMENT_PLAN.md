# ğŸš€ Plan de Despliegue - LÃ­mites de Tokens para MÃºltiples Sentencias

## ğŸ“‹ Resumen
ActualizaciÃ³n de la aplicaciÃ³n para procesar mÃºltiples sentencias judiciales simultÃ¡neamente, ampliando los lÃ­mites de tokens de 4,000 a 32,000 (por defecto) y hasta 128,000 (mÃ¡ximo).

## ğŸ¯ Objetivo
Permitir el procesamiento de hasta **10-12 sentencias judiciales** de 2-3 pÃ¡ginas cada una en una sola consulta.

## âœ… Cambios Aplicados

### 1. **Modelos de Datos** (`user_agent.py`)
- âœ… **Valor por defecto**: `32,000 tokens` (antes 1,000)
- âœ… **LÃ­mite mÃ¡ximo**: `128,000 tokens` (antes 4,000)
- âœ… **ValidaciÃ³n**: `ge=1, le=128000`

### 2. **Servicios** (`user_agent_service.py`)
- âœ… **ConfiguraciÃ³n por defecto**: `32,000 tokens`
- âœ… **Valor de fallback**: `32,000 tokens` (antes 1,000)

### 3. **Servicio Gradient AI** (`gradient_service.py`)
- âœ… **Timeout principal**: `120 segundos` (antes 30)
- âœ… **Test de conexiÃ³n**: `50 tokens` (antes 10)

### 4. **Endpoints** (`agent_endpoints.py`)
- âœ… **Endpoint /models**: Muestra `128,000` como capacidad mÃ¡xima
- âœ… **Preset sentencias**: `32,000 tokens` por defecto
- âœ… **Presets adicionales**: Configuraciones escaladas

## ğŸ“Š Capacidades por Escenario

| Escenario | Sentencias | PÃ¡ginas | Tokens | ConfiguraciÃ³n |
|-----------|------------|---------|--------|---------------|
| **BÃ¡sico** | 1-3 | 2-9 | 5,000-15,000 | Por defecto (32K) |
| **EstÃ¡ndar** | 5-8 | 10-24 | 20,000-32,000 | Por defecto (32K) |
| **Avanzado** | 10-12 | 20-36 | 40,000-48,000 | Por defecto (32K) |
| **Extremo** | 15+ | 30+ | 60,000+ | Manual (64K-128K) |

## ğŸ”§ Scripts de Despliegue

### 1. **VerificaciÃ³n** (Ya ejecutado)
```bash
./scripts/verify_token_limits.sh
```
**Estado**: âœ… Completado - Todos los cambios verificados

### 2. **Despliegue Local** (Opcional)
```bash
cd backend
pip install -r requirements.txt
uvicorn api.main:app --reload
```

### 3. **Despliegue a ProducciÃ³n**
```bash
./scripts/deploy.sh
```

## ğŸ§ª Pruebas Recomendadas

### 1. **Prueba BÃ¡sica** (1-3 sentencias)
```bash
curl -X POST "http://localhost:8000/api/v1/agent/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Analiza estas 3 sentencias: [contenido de 3 sentencias]",
    "user_id": "test_user"
  }'
```

### 2. **Prueba EstÃ¡ndar** (5-8 sentencias)
```bash
curl -X POST "http://localhost:8000/api/v1/agent/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Compara estas 8 sentencias: [contenido de 8 sentencias]",
    "user_id": "test_user"
  }'
```

### 3. **Prueba de LÃ­mite** (10+ sentencias)
```bash
curl -X PUT "http://localhost:8000/api/v1/agent/config/test_user" \
  -H "Content-Type: application/json" \
  -d '{"max_tokens": 64000}'
```

## ğŸ“ˆ Monitoreo Post-Despliegue

### 1. **MÃ©tricas a Observar**
- Tiempo de respuesta promedio
- Uso de tokens por consulta
- Tasa de errores de timeout
- Costos de API

### 2. **Alertas Recomendadas**
- Timeout > 100 segundos
- Uso de tokens > 100,000 por consulta
- Tasa de error > 5%

## âš ï¸ Consideraciones Importantes

### 1. **Costos**
- **32K tokens** â‰ˆ 2-3x mÃ¡s caro que 4K tokens
- **128K tokens** â‰ˆ 8-10x mÃ¡s caro que 4K tokens
- Monitorear uso y ajustar segÃºn presupuesto

### 2. **Rendimiento**
- Respuestas mÃ¡s largas = mayor tiempo de procesamiento
- Timeout de 120s deberÃ­a ser suficiente
- Considerar procesamiento asÃ­ncrono para casos extremos

### 3. **LÃ­mites del Modelo**
- `openai-gpt-oss-120b` soporta hasta 128,000 tokens
- ConfiguraciÃ³n actual estÃ¡ dentro de los lÃ­mites
- No requiere cambio de modelo

## ğŸ¯ PrÃ³ximos Pasos

1. **Desplegar a producciÃ³n** usando `./scripts/deploy.sh`
2. **Ejecutar pruebas** con diferentes volÃºmenes de sentencias
3. **Monitorear mÃ©tricas** durante las primeras 24-48 horas
4. **Ajustar configuraciÃ³n** segÃºn el uso real observado

## ğŸ“ Soporte

Si encuentras problemas:
1. Verificar logs de la aplicaciÃ³n
2. Revisar mÃ©tricas de uso de tokens
3. Ajustar timeout si es necesario
4. Considerar procesamiento por lotes para casos extremos

---
**Estado**: âœ… Listo para despliegue
**Fecha**: $(date)
**VersiÃ³n**: 1.0.0
